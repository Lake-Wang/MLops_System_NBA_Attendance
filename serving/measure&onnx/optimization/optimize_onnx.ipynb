{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f71362c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import neural_compressor\n",
    "from neural_compressor import quantization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8011bd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = os.getenv(\"NBA_TEST_DATA\", \"nba_test.csv\")\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "X = df.drop(columns=['score_diff']).values\n",
    "y = df['score_diff'].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "test_dataset = TensorDataset(X_tensor, y_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5b7302",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_session(ort_session):\n",
    "    print(f\"Execution provider: {ort_session.get_providers()}\")\n",
    "\n",
    "    total_mae = 0\n",
    "    total = 0\n",
    "    for features, labels in test_loader:\n",
    "        outputs = ort_session.run(None, {ort_session.get_inputs()[0].name: features.numpy()})[0]\n",
    "        mae = np.abs(outputs - labels.numpy()).sum()\n",
    "        total_mae += mae\n",
    "        total += labels.size(0)\n",
    "    print(f\"Mean Absolute Error (MAE): {total_mae / total:.2f}\")\n",
    "\n",
    "    num_trials = 100\n",
    "    single_sample = X_tensor[0].unsqueeze(0).numpy()\n",
    "    ort_session.run(None, {ort_session.get_inputs()[0].name: single_sample})\n",
    "    latencies = []\n",
    "    for _ in range(num_trials):\n",
    "        start = time.time()\n",
    "        ort_session.run(None, {ort_session.get_inputs()[0].name: single_sample})\n",
    "        latencies.append(time.time() - start)\n",
    "    print(f\"Inference Latency (median): {np.percentile(latencies, 50) * 1000:.2f} ms\")\n",
    "    print(f\"Inference Throughput: {num_trials / np.sum(latencies):.2f} FPS\")\n",
    "\n",
    "    num_batches = 50\n",
    "    batch_input = X_tensor[:32].numpy()\n",
    "    ort_session.run(None, {ort_session.get_inputs()[0].name: batch_input})\n",
    "    batch_times = []\n",
    "    for _ in range(num_batches):\n",
    "        start = time.time()\n",
    "        ort_session.run(None, {ort_session.get_inputs()[0].name: batch_input})\n",
    "        batch_times.append(time.time() - start)\n",
    "    print(f\"Batch Throughput: {(batch_input.shape[0] * num_batches) / np.sum(batch_times):.2f} FPS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1c3f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model_path = \"models/nba_model.onnx\"\n",
    "optimized_model_path = \"models/nba_model_optimized.onnx\"\n",
    "\n",
    "session_options = ort.SessionOptions()\n",
    "session_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_EXTENDED\n",
    "session_options.optimized_model_filepath = optimized_model_path\n",
    "\n",
    "ort_session = ort.InferenceSession(onnx_model_path, sess_options=session_options, providers=['CPUExecutionProvider'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26063425",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model_path = \"models/nba_model_optimized.onnx\"\n",
    "ort_session = ort.InferenceSession(onnx_model_path, providers=['CPUExecutionProvider'])\n",
    "benchmark_session(ort_session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a25ced3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"models/nba_model.onnx\"\n",
    "fp32_model = neural_compressor.model.onnx_model.ONNXModel(model_path)\n",
    "\n",
    "config_ptq = neural_compressor.PostTrainingQuantConfig(approach=\"dynamic\")\n",
    "\n",
    "q_model = quantization.fit(model=fp32_model, conf=config_ptq)\n",
    "\n",
    "q_model.save_model_to_file(\"models/nba_model_quantized_dynamic.onnx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a628e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model_path = \"models/nba_model_quantized_dynamic.onnx\"\n",
    "print(f\"Model Size on Disk: {os.path.getsize(onnx_model_path) / 1e6:.2f} MB\")\n",
    "ort_session = ort.InferenceSession(onnx_model_path, providers=['CPUExecutionProvider'])\n",
    "benchmark_session(ort_session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8f68be",
   "metadata": {},
   "outputs": [],
   "source": [
    "calib_dataset = neural_compressor.data.datasets.NumpyDataset(X_tensor.numpy())\n",
    "calib_dataloader = neural_compressor.data.DataLoader(framework='onnxruntime', dataset=calib_dataset)\n",
    "\n",
    "config_static_aggressive = neural_compressor.PostTrainingQuantConfig(\n",
    "    accuracy_criterion=neural_compressor.config.AccuracyCriterion(criterion=\"absolute\", tolerable_loss=0.05),\n",
    "    approach=\"static\",\n",
    "    device='cpu',\n",
    "    quant_level=1,\n",
    "    quant_format=\"QOperator\",\n",
    "    recipes={\"graph_optimization_level\": \"ENABLE_EXTENDED\"},\n",
    "    calibration_sampling_size=128\n",
    ")\n",
    "\n",
    "q_model = quantization.fit(\n",
    "    model=fp32_model,\n",
    "    conf=config_static_aggressive,\n",
    "    calib_dataloader=calib_dataloader,\n",
    "    eval_dataloader=calib_dataloader\n",
    ")\n",
    "\n",
    "q_model.save_model_to_file(\"models/nba_model_quantized_aggressive.onnx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48eba4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model_path = \"models/nba_model_quantized_aggressive.onnx\"\n",
    "print(f\"Model Size on Disk: {os.path.getsize(onnx_model_path) / 1e6:.2f} MB\")\n",
    "ort_session = ort.InferenceSession(onnx_model_path, providers=['CPUExecutionProvider'])\n",
    "benchmark_session(ort_session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29493e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_static_conservative = neural_compressor.PostTrainingQuantConfig(\n",
    "    accuracy_criterion=neural_compressor.config.AccuracyCriterion(criterion=\"absolute\", tolerable_loss=0.01),\n",
    "    approach=\"static\",\n",
    "    device='cpu',\n",
    "    quant_level=0,\n",
    "    quant_format=\"QOperator\",\n",
    "    recipes={\"graph_optimization_level\": \"ENABLE_EXTENDED\"},\n",
    "    calibration_sampling_size=128\n",
    ")\n",
    "\n",
    "q_model = quantization.fit(\n",
    "    model=fp32_model,\n",
    "    conf=config_static_conservative,\n",
    "    calib_dataloader=calib_dataloader,\n",
    "    eval_dataloader=calib_dataloader\n",
    ")\n",
    "\n",
    "q_model.save_model_to_file(\"models/nba_model_quantized_conservative.onnx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f70236",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model_path = \"models/nba_model_quantized_conservative.onnx\"\n",
    "print(f\"Model Size on Disk: {os.path.getsize(onnx_model_path) / 1e6:.2f} MB\")\n",
    "ort_session = ort.InferenceSession(onnx_model_path, providers=['CPUExecutionProvider'])\n",
    "benchmark_session(ort_session)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": "3"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
